from selenium import webdriver
from selenium.webdriver.edge.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pickle
import os
import time
import random

class TaobaoScraperNew:
    def __init__(self, 
                 driver_path: str,
                 user_data_dir: str = r"C:\taobao_bot_profile",
                 cookie_file: str = "taobao_cookies.pkl"):
        """
        åˆå§‹åŒ–çˆ¬è™«å®ä¾‹
        
        :param driver_path: Edgeé©±åŠ¨è·¯å¾„
        :param user_data_dir: ç”¨æˆ·æ•°æ®å­˜å‚¨ç›®å½• (é»˜è®¤C:\taobao_bot_profile)
        :param cookie_file: Cookieå­˜å‚¨æ–‡ä»¶å (é»˜è®¤taobao_cookies.pkl)
        """
        self.driver = None
        self.driver_path = driver_path
        self.user_data_dir = user_data_dir
        self.cookie_file = cookie_file

    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å…¥å£"""
        self.initialize_driver()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å‡ºå£"""
        self.close()

    def initialize_driver(self):
        """åˆå§‹åŒ–æµè§ˆå™¨é©±åŠ¨"""
        options = webdriver.EdgeOptions()
        options.use_chromium = True
        
        if not os.path.exists(self.user_data_dir):
            os.makedirs(self.user_data_dir)
        options.add_argument(f"user-data-dir={self.user_data_dir}")
        
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option("useAutomationExtension", False)
        
        self.driver = webdriver.Edge(
            service=Service(self.driver_path),
            options=options
        )

    def check_login_status(self) -> bool:
        """éªŒè¯ç™»å½•çŠ¶æ€"""
        try:
            self.driver.get("https://www.taobao.com")
            WebDriverWait(self.driver, 15).until(
                EC.presence_of_element_located((By.LINK_TEXT, "æˆ‘çš„æ·˜å®"))
            )
            return True
        except Exception as e:
            print(f"ğŸš¨ ç™»å½•çŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False

    def manual_login(self):
        """æ‰§è¡Œæ‰‹åŠ¨ç™»å½•æµç¨‹"""
        print("ğŸ‘‰ è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š")
        print("1ï¸âƒ£ è®¿é—® https://login.taobao.com")
        print("2ï¸âƒ£ ä½¿ç”¨æ‰‹æœºæ·˜å®æ‰«ç å®Œæˆç™»å½•")
        print("3ï¸âƒ£ ç™»å½•æˆåŠŸåä¿æŒé¡µé¢ä¸åŠ¨")
        
        self.driver.get("https://login.taobao.com")
        input("ğŸ”„ å®Œæˆç™»å½•åæŒ‰å›è½¦ç»§ç»­...")
        
        if not self.check_login_status():
            raise RuntimeError("âŒ æ‰‹åŠ¨ç™»å½•éªŒè¯å¤±è´¥")
        
        with open(self.cookie_file, 'wb') as f:
            pickle.dump(self.driver.get_cookies(), f)
        print("âœ… ç™»å½•å‡­è¯å·²å­˜å‚¨")

    def load_cookies(self) -> bool:
        """åŠ è½½æŒä¹…åŒ–Cookie"""
        if os.path.exists(self.cookie_file):
            try:
                with open(self.cookie_file, 'rb') as f:
                    cookies = pickle.load(f)
                    self.driver.delete_all_cookies()
                    for cookie in cookies:
                        self.driver.add_cookie(cookie)
                self.driver.refresh()
                print("ğŸ”‘ å†å²CookieåŠ è½½å®Œæˆ")
                return True
            except Exception as e:
                print(f"âŒ CookieåŠ è½½å¼‚å¸¸: {str(e)}")
                return False
        return False

    def ensure_login(self):
        """ç¡®ä¿ç™»å½•çŠ¶æ€"""
        if not self.check_login_status():
            print("âš ï¸ æ£€æµ‹åˆ°ç™»å½•çŠ¶æ€å¤±æ•ˆï¼Œå°è¯•æ¢å¤...")
            if not self.load_cookies() or not self.check_login_status():
                self.manual_login()

    def smart_scroll(self) -> bool:
        """æ™ºèƒ½æ»šåŠ¨åŠ è½½"""
        scroll_container = self.driver.execute_script("""
            return document.querySelector("body > div[class*='7efaeec'] > div[class*='e320bf32'] > div > div[class*='00182ac']") 
            || document.documentElement
        """)
        
        try:
            pre_count = len(self.driver.find_elements(By.XPATH, "//*[contains(@class, '0b4e753')]"))
            
            self.driver.execute_script("""
                arguments[0].scrollTop += arguments[0].clientHeight * 8.5;
            """, scroll_container)
            
            time.sleep(random.uniform(0.1, 0.3))  
            
            post_count = len(self.driver.find_elements(By.XPATH, "//*[contains(@class, '0b4e753')]"))
            print(f"ğŸ”„ æ»šåŠ¨æ£€æµ‹: {pre_count} â†’ {post_count} æ¡è¯„è®º")
            return post_count > pre_count
        except Exception as e:
            print(f"âŒ æ»šåŠ¨å¼‚å¸¸: {str(e)}")
            return False

    def scrape_reviews(self, product_url: str, output_file: str, max_comments: int = 1000):
        """
        æ‰§è¡Œè¯„ä»·çˆ¬å–
        
        :param product_url: å•†å“è¯¦æƒ…é¡µURL
        :param output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        :param max_comments: æœ€å¤§æ”¶é›†æ•°é‡ (é»˜è®¤1000)
        """
        self.driver.get(product_url)
        time.sleep(3)
        
        try:
            review_btn = WebDriverWait(self.driver, 40).until(
                EC.element_to_be_clickable((By.XPATH, "//*[contains(@class, '15e2446')]"))
            )
            self.driver.execute_script("arguments[0].click();", review_btn)
            time.sleep(3)
        except Exception as e:
            raise RuntimeError(f"ğŸš« æ— æ³•æ‰“å¼€è¯„ä»·é¡µé¢: {str(e)}")
        
        processed = set()
        retry_count = 0
        max_retries = 5
        collected_enough = False  # æ”¶é›†å®ŒæˆçŠ¶æ€æ ‡è¯†

        with open(output_file, 'w', encoding='utf-8') as f:
            while retry_count < max_retries and not collected_enough:
                current_comments = self.driver.find_elements(By.XPATH, "//*[contains(@class, '0b4e753')]")
                new_added = 0
                
                # å¤„ç†å½“å‰é¡µè¯„è®º
                for comment in current_comments:
                    comment_id = comment.get_attribute('data-before-current-y')
                    if comment_id not in processed:
                        try:
                            content = comment.find_element(By.XPATH, ".//*[contains(@class, 'content')]").text
                            f.write(content + '\n')
                            processed.add(comment_id)
                            new_added += 1
                            
                            if len(processed) >= max_comments:
                                collected_enough = True
                                break
                        except Exception as e:
                            print(f"âš ï¸ è¯„è®ºå¤„ç†å¼‚å¸¸: {str(e)}")
                            continue
                
                # è¾¾åˆ°æ•°é‡åç«‹å³ç»ˆæ­¢
                if collected_enough:
                    print(f"ğŸ‰ æˆåŠŸæ”¶é›† {max_comments} æ¡è¯„è®ºï¼Œä»»åŠ¡å®Œæˆ")
                    break
                
                # æ»šåŠ¨æ§åˆ¶é€»è¾‘
                if new_added < 5:
                    retry_count += 1
                    print(f"ğŸ”„ æ–°å¢è¯„è®ºä¸è¶³({new_added}æ¡)ï¼Œå‡†å¤‡ç¬¬{retry_count}æ¬¡é‡è¯•...")
                else:
                    retry_count = 0
                
                # æ‰§è¡Œæ»šåŠ¨
                if not self.smart_scroll():
                    retry_count += 1
                    print(f"ğŸ”„ æ»šåŠ¨æœªåŠ è½½æ–°å†…å®¹ï¼Œå‡†å¤‡ç¬¬{retry_count}æ¬¡é‡è¯•...")
                
                # åŠ¨æ€ç­‰å¾…ç­–ç•¥
                delay = 1.2 if new_added > 0 else 2.0
                time.sleep(delay)
                
                # æœ€ç»ˆç»ˆæ­¢æ£€æŸ¥
                if retry_count >= max_retries:
                    print(f"ğŸ›‘ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°{max_retries}ï¼Œç»ˆæ­¢æ”¶é›†")
                    break

    def close(self):
        """å…³é—­æµè§ˆå™¨å®ä¾‹"""
        if self.driver:
            self.driver.quit()
            print("ğŸ›‘ æµè§ˆå™¨å®ä¾‹å·²å…³é—­")
            if os.path.exists(self.cookie_file):
                os.remove(self.cookie_file)
                print("ğŸ§¹ ä¸´æ—¶Cookieæ–‡ä»¶å·²æ¸…ç†")

# ä¿ç•™ç‹¬ç«‹è¿è¡ŒåŠŸèƒ½
if __name__ == "__main__":
    with TaobaoScraperNew(
        driver_path=r"E:\edgedriver_win64 (1)\msedgedriver.exe"
    ) as scraper:
        scraper.ensure_login()
        scraper.scrape_reviews(
            product_url=input("ğŸ›ï¸ è¯·è¾“å…¥å•†å“è¯¦æƒ…é¡µé“¾æ¥: ").strip(),
            output_file='D:\C_data\AIGC\å…¨éƒ¨è¯„ä»·.txt',
            max_comments=1000  # å¯ä¿®æ”¹ä¸ºå…¶ä»–æ•°å€¼
        )
